In order to evaluate the effects of the proposed discretizations of \SUTwo the so called Metropolis Monte Carlo Method was used. The goal of this method is estimate the expectaion value of an Operator $\mathcal{O}$ by numerically evaluating the path integral given by
\begin{align*}
 \left\langle \mathcal{O} \right\rangle & = \frac{1}{Z}\int \left( \prod_\mu \mathcal{D} U_\mu \right) \, \mathcal{O} \exp \left( - S_G^{(\textrm{eucl.})}(U)\right) \\
 \textrm{with} \qquad Z                 & = \int \left( \prod_\mu \mathcal{D} U_\mu \right) \exp \left( - S_G^{(\textrm{eucl.})}(U)\right)
\end{align*}
This is done by randomly generating lattice configurations $\boldsymbol{U} \equiv \{ U_\mu(n) \}$ with a probability distribution given by
\begin{align}
 \rho ( \boldsymbol{U} ) = \frac{\exp\left(  -S_G^{(\textrm{eucl.})}(\boldsymbol{U}) \right)}{Z} \textrm{.}
 \label{eq:metroDist}
\end{align}
For a set of $N$ configurations $\{ \boldsymbol{U}^i \}$ the expectation value of $\mathcal{O}$ is then obtained by a simple arithmetic average
\begin{align*}
 \left\langle \mathcal{O} \right\rangle & = \frac{1}{N} \sum_{\boldsymbol{U} \in \{ \boldsymbol{U}^i \}} \mathcal{O} (\boldsymbol{U}) \textrm{.}
\end{align*}

There are numerous ways of generating lattice configurations $\{ \boldsymbol{U}^i \}$. A popular choice is the so called \emph{Metropolis algorithm} first proposed in \cite{metropolis:1953} and applied to quantum simulations in \cite{Creutz:1981}. A simple implementation can be found in algorithm \ref{alg:metroMonte}.

\begin{algorithm}[!htb]
 \caption{Metropolis Monte Carlo}
 \label{alg:metroMonte}
 \begin{algorithmic}[1]
  \STATE {$\left\langle \mathcal{O} \right\rangle := 0$}
  \STATE {$\boldsymbol{U}$ = (\textrm{Some initial Lattice configuration})}
  \FOR {$N$ iterations}
  \FORALL {$U_\mu(n) \in \boldsymbol{U}$ }
  \COMMENT {Iteration over all link variables}
  \STATE {$\boldsymbol{U}' := \boldsymbol{U}$}
  \COMMENT {Copy the configuration $\boldsymbol{U}$ into a new}
  \STATE {}
  \COMMENT {\hspace{3mm} configuration $\boldsymbol{U}'$}

  \STATE {$U'_\mu(n) \leftarrow U_{\textrm{rand}}$}
  \COMMENT {Replace $U'_\mu(n)$ with a random }
  \STATE {}
  \COMMENT {\hspace{3mm} member of the gauge set $U_{\textrm{rand}} \in G$}
  \STATE {$\Delta S := S_G^{(\textrm{eucl.})} (\boldsymbol{U}) - S_G^{(\textrm{eucl.})} (\boldsymbol{U}')$}
  \COMMENT {Calculate the difference in action}
  \STATE {}
  \COMMENT {\hspace{3mm} for the transition $\boldsymbol{U} \rightarrow \boldsymbol{U}'$}
  \IF {$\Delta S < 0 \, \lor \, \exp \left(- \Delta S \right) > r$}
  \label{code:metroMonteIfCond}
  \COMMENT {with $0 \le r \le 1$ beeing a random}
  \STATE {}
  \COMMENT {\hspace{3mm} number with uniform distribution}
  \STATE $\boldsymbol{U} \leftarrow \boldsymbol{U}'$
  \COMMENT {replace $\boldsymbol{U}$ with $\boldsymbol{U}'$}
  \ENDIF

  \ENDFOR
  \STATE $\left\langle \mathcal{O} \right\rangle \leftarrow \left\langle \mathcal{O} \right\rangle + \frac{\mathcal{O}(\boldsymbol{U})}{N} $
  \COMMENT {Measure $\mathcal{O}(\boldsymbol{U})$}
  \ENDFOR
 \end{algorithmic}
\end{algorithm}
As an initial configuration one usually either chooses a cold starting configuration, i.e. {$U_\mu(n)=1$} or a hot one where every link variable is set to a random element of \SUTwo. After that it takes numerous Iterations until the configuration reaches \emph{thermal equilibrium}. A common way to figure out how many iterations this takes, is to run the simulation once with a hot and once with a cold start, and see where the measured values start to agree.

After equilibrium is reached every succesive iteration will generate a new random lattice configuration distributed according to eq. \ref{eq:metroDist}. Therefore $\left\langle \mathcal{O} \right\rangle$ can then be measured to arbitrary precision by simply generating a sufficient amount of lattice configurations. The only limit to this would be the finite precision of flotaing point operations on digital computers, as well as the limited randomness of pseudo random number generators.

A key element of such simulations takes place in line \ref{code:metroMonteIfCond} with the generation of a new random element. The implementation of this for the continuous as well as the discrete case will be presented in the following sections

\subsection{The Continous Case}
The first idea that comes to mind for the continuous case is just to pick a random point on the sphere. Procedures to find uniformly distributed random points on spheres of arbitrary dimensions are well known \cite{findsource}. One such procedure to get the euclidian coordinates $x_{\textrm{rand}}$ of a random point on $S_n$ would be given by
\begin{align}
 x_{\textrm{rand}} = \frac{1}{\sqrt{\sum_{i=1}^{n+1}(x^i_{\textrm{rand}})^2}} \begin{pmatrix}
  x^1_{\textrm{rand}} \\
  x^2_{\textrm{rand}} \\
  \vdots              \\
  x^{n+1}_{\textrm{rand}}
 \end{pmatrix}
 \label{eq:randSpherePoint}
\end{align}
where $\{x^i_{\textrm{rand}}\}$ are random numbers generated by a normal distribution with expectaion value $\mu = 0$ and an arbitrary standard deviation $\sigma \neq 0$.

The problem with this approach is that for high values of $\beta$ line \ref{code:metroMonteIfCond} in the algorithm will quite often evaluate to \texttt{false}, as $\Delta S$ is likely to be big. This leads to little change in the configuration per iteration, and therefore high run times to generate sufficient statistics.

This is why one usually aims to generate an element $U_\mu^{\textrm{new}}(n)$ which is in the vicinity of the old element $U_\mu^{\textrm{old}}$. This achieved by
\begin{align*}
 U_\mu^{\textrm{new}}(n) = V \, U_\mu^{\textrm{old}} (n)
\end{align*}
where $V$ is a random group element within the angular distance $2  \pi \delta$ of $1$. $V$ can be found as
\begin{align}
 V = \cos (2 \pi d ) + \sin (2 \pi d) \left(i x_1  + j x_2  + k x_3\right)
 \label{eq:transitionV}
\end{align}
where $d$ is a random number uniformly distributed within the interval $[0,\delta]$ and $(x_1,x_2,x_3)$ are a random point on $S_2$ found by applying eq. \ref{eq:randSpherePoint}.

%The parameter $\delta$ therefore controls how close $V$ to $1$ is, and thus also how close $U^{\textrm{new}}$ to $U^{\textrm{old}}$ is. Generally one a
\subsection{Finite Gauge Sets}

Furthermore we need to deal with finite gauge sets $G$. As proposed in \ref{Petcher:1980} one can employ a similar procedure to the continuous case for the finite subgroups of \SUTwo by simply setting $V$ to a random element of the group adjacent to $1$. These would be given by the elements $N(G)$ that minimize the value of $\norm{V - 1}$ and can explicitly found in table \ref{tab:adjacentGenerators}.
\begin{table}
 \centering
 \begin{tabu}{c|l}
  $G$            & $N(G)$ $1$                                                                                                                                                                     \\
  \hline
  $C_{16}$       & $\left\{ \pm i, \pm j, \pm k \right \}$                                                                                                                                        \\
  \hline
  $\overline{O}$ & $\left\{ \frac{1}{2}(1 + a) \middle| a \in \left\{ \textrm{sing comb. of } \pm i \pm j \pm k \right\} \right\}$                                                                \\
  \hline
  $\overline{T}$ & $\left\{ \frac{1}{\sqrt{2}}\left(1 \pm a \right) \middle| a \in \{ i,j,k \} \right\}$                                                                                          \\
  \hline
  $\overline{I}$ & $\left\{ \frac{1}{2} \left( \tau + a \right) \middle| a \in \left\{ \textrm{sign comb. and even perm. of }  \left( \pm 0i \pm 1 j \pm \frac{k}{\tau} \right)\right\} \right\}$ \\
 \end{tabu}
 \caption{caption}
 \label{tab:adjacentGenerators}
\end{table}
Multiplying them from the left amounts to a small rotation, mapping all vertices to one of their adjacent vertices.\\

All other lattices do not posses group properties, so the transition to a neighbouring vertex needs to be implemented in another way. In the case of $C_5$ all five vertices are adjacent to one another, so one can simply pick $U^{\textrm{new}}_\mu$ from one of the four vertices that is not $U^{\textrm{old}}_\mu$.\\

Finding the four adjacent vertices of a given vertex of $C_{120}$ is a less trivial task. As quaternionic multiplication from the left can be interpreted as a rotation in $\mathbb{R}^4$ the construction of $C_{120}$ found in table \ref{tab:polytopes} suggest that the vertices of $C_{120}$ are given by the vertices of $\overline{I}$ as well as four rotated copies of it. In order to keep track of where we are on $C_{120}$ we can therefore just keep track of where we are on $\overline{I}$ (for which we can make use of the group properties) and whether one of the four rotations needs to be applied.

Unfortunately we can not use the five elements of $C_5$ as these rotations, as they implement rotations by about $\cos^{-1}\left({\frac{1}{4}}\right) \approx \SI{75}{^\circ}$ and therefore will most certainly not map a vertex of $\overline{I}$ to an adjacent one of $C_{120}$.

In order to obtain a useful set of rotation matrices we take a look at the vertices $1,i,j$ and $k$ of $\overline{I}$. As these translate to the basis vectors of $\mathbb{R}^4$ the columns of the rotation matrices must be given by the neighbours of these vertices. To figure out which of the $(4!)^3 = 13824$ combinations of these columns leads to the right matrices a brute force symbolic calculation was used. This indeed gave a unique solution given by
\begin{align*}
  & R = \left\{
 \begin{bmatrix}
  \rho    & \theta  & \theta  & \theta  \\
  -\theta & \rho    & -\theta & \theta  \\
  -\theta & \theta  & \rho    & -\theta \\
  -\theta & -\theta & \theta  & \rho    \\
 \end{bmatrix},
 \begin{bmatrix}
  \rho    & -\theta & \theta  & -\theta \\
  \theta  & \rho    & \theta  & \theta  \\
  -\theta & -\theta & \rho    & \theta  \\
  \theta  & -\theta & -\theta & \rho    \\
 \end{bmatrix},
 \begin{bmatrix}
  \rho    & \theta  & -\theta & -\theta \\
  -\theta & \rho    & \theta  & -\theta \\
  \theta  & -\theta & \rho    & -\theta \\
  \theta  & \theta  & \theta  & \rho    \\
 \end{bmatrix},
 \begin{bmatrix}
  \rho    & -\theta & -\theta & \theta  \\
  \theta  & \rho    & -\theta & -\theta \\
  \theta  & \theta  & \rho    & \theta  \\
  -\theta & \theta  & -\theta & \rho    \\
 \end{bmatrix}
 \right\}
\end{align*}
with
\begin{align*}                                                                   \rho = \frac{1 + 3\sqrt{5}}{8} \qquad \textrm{and} \qquad \theta = \frac{1-\sqrt{5}}{8} \textrm{.}
\end{align*}
To implement this we introduced a rotation index $r \in \{0,1,2,3,4\}$ which indicates by which of the four matrices in $R$ the vertex $U \in \overline{I}$ needs to be rotated. $r=4$ covers the case that no rotation needs to be applied. With this we can then implement the following algorithm, to get one of the four adjacent vertices of $C_{120}$, in terms of the old vertex specified by $r_{\textrm{old}}$ and $U_{\textrm{old}}$, as well as a random integer $0 \le d_{\textrm{rand}} \le 3$.
\begin{algorithm}[!htb]
 \caption{Neighbour Vertex Algorithm}
 \label{alg:120CellVertexPick}
 \begin{algorithmic}[1]
  \REQUIRE $U_{\textrm{old}} \in \overline{I}, \quad r_{\textrm{old}}\in \left\{ 0,1,2,3,4\right\}, \quad d_{\textrm{rand}} \in \left\{0,1,2,3 \right\}$
  \IF {$r_{\textrm{old}} = 4$}
  \COMMENT {The current vertex is also a vertex of $\overline{I}$.}
  \STATE $r_{\textrm{new}} \leftarrow d_{\textrm{rand}}$
  \COMMENT {\hspace{3mm} Therefore we pick a random rotation}
  \STATE $U_{\textrm{new}} \leftarrow U_{\textrm{old}}$
  \COMMENT {\hspace{3mm} matrix and leave $u$ unchanged}
  \ELSIF {$d_{\textrm{rand}} = 3$}
  \COMMENT{If the current vertex is on one of the}
  \STATE $r_{\textrm{new}} \leftarrow 4$
  \COMMENT{\hspace{3mm} rotated copies of $\overline{I}$, there is a one}
  \STATE $U_{\textrm{new}} \leftarrow U_{\textrm{old}}$
  \COMMENT{\hspace{3mm} in four chance of it rotating back}
  \ELSE
  \STATE $r_{\textrm{new}} \leftarrow r_{\textrm{old}} + d_{\textrm{rand}} + 1 \quad \mathrm{mod} \quad 4$
  \COMMENT {Pick a new rotation index s.t. $r_{\textrm{new}} \neq r_{\textrm{old}}$}
  \FOR {$V \in N(\overline{I})$}
  \IF {$\textrm{isNeighbour}\left( r_{\textrm{new}} ,  V U_{\textrm{old}}\right)$}
  \COMMENT {Check whether $r_{\textrm{new}}$ and $V U_{\textrm{old}}$ give rise}
  \STATE $U_{\textrm{new}} \leftarrow V U_{\textrm{old}}$
  \COMMENT {\hspace{3mm} to an adjacent vertex}
  \STATE \textbf{break}
  \ENDIF
  \ENDFOR
  \ENDIF
  \RETURN $U_{\textrm{new}}, \, r_{\textrm{new}}$
 \end{algorithmic}
\end{algorithm}

Next up is $V_n$. For this we simply keep track of the corresponding vertex of $\tilde{V}_n$, as addition or subtraction of $\frac{1}{n+1}$ to any component of a given vertex, will lead to an adjacent vertex. The only restriction to this would be, that all components need to be within the interval $\left[-\frac{1}{2},\frac{1}{2}\right]$, as well as that at least one component needs to equal $\pm \frac{1}{2}$. For $n = 0$ this also covers $C_8$.\\

Lastly we are left with the fibonacci lattice. As maybe best seen in \ref{fig:fibonacciPic} the notion of an adjacent vertex is quite hard to define for the fibonacci lattice, as the amount of adjacent vertices, as well as their exact distances vary for each vertex. Therefore here we went with the less elegant approach of picking a random element from the whole lattice.


% \begin{itemize}
%   \item Vielleicht nützlich \url{https://link.springer.com/content/pdf/10.1007/BF01548769.pdf}
% \end{itemize}


%  https://journals.aps.org/prd/pdf/10.1103/PhysRevD.22.2465
