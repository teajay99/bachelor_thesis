In order to evaluate the effects of the proposed discretizations of \SUTwo the so called Metropolis Monte Carlo Method was used. The goal of this method is estimate the expectaion value of an Operator $\mathcal{O}$ by numerically evaluating the path integral given by
\begin{align*}
 \left\langle \mathcal{O} \right\rangle & = \frac{1}{Z}\int \left( \prod_\mu \mathcal{D} U_\mu \right) \, \mathcal{O} \exp \left( - S_G^{(\textrm{eucl.})}(U)\right) \\
 \textrm{with} \qquad Z                 & = \int \left( \prod_\mu \mathcal{D} U_\mu \right) \exp \left( - S_G^{(\textrm{eucl.})}(U)\right)
\end{align*}
This is done by randomly generating lattice configurations $\boldsymbol{U} \equiv \{ U_\mu(n) \}$ with a probability distribution given by
\begin{align*}
 \rho ( \boldsymbol{U} ) = \frac{\exp\left(  -S_G^{(\textrm{eucl.})}(\boldsymbol{U}) \right)}{Z} \textrm{.}
\end{align*}
For a set of $N$ configurations $\{ \boldsymbol{U}^i \}$ the expectation value of $\mathcal{O}$ is then obtained by a simple arithmetic average
\begin{align*}
 \left\langle \mathcal{O} \right\rangle & = \frac{1}{N} \sum_{\boldsymbol{U} \in \{ \boldsymbol{U}^i \}} \mathcal{O} (\boldsymbol{U}) \textrm{.}
\end{align*}

There are numerous ways of generating lattice configurations $\{ \boldsymbol{U}^i \}$. A popular choice is the so called \emph{Metropolis algorithm} first proposed in \cite{metropolis:1953} and applied to quantum simulations in \cite{Creutz:1981}. A simple implementation can be found in algorithm \ref{alg:metroMonte}.

\begin{algorithm}[!htb]
 \caption{Metropolis Monte Carlo}
 \label{alg:metroMonte}
 \begin{algorithmic}[1]
  \STATE {$\left\langle \mathcal{O} \right\rangle := 0$}
  \STATE {$\boldsymbol{U}$ = (\textrm{Some initial Lattice configuration})}
  \FOR {$N$ iterations}
  \FORALL {$U_\mu(n) \in \boldsymbol{U}$ }
  \COMMENT {Iteration over all link variables}
  \STATE {$\boldsymbol{U}' := \boldsymbol{U}$}
  \COMMENT {Copy the configuration $\boldsymbol{U}$ into a new}
  \STATE {}
  \COMMENT {\hspace{3mm} configuration $\boldsymbol{U}'$}

  \STATE {$U'_\mu(n) \rightarrow U_{\textrm{rand}}$}
  \COMMENT {Replace $U'_\mu(n)$ with a random }
  \STATE {}
  \COMMENT {\hspace{3mm} member of the gauge set $U_{\textrm{rand}} \in G$}
  \STATE {$\Delta S := S_G^{(\textrm{eucl.})} (\boldsymbol{U}) - S_G^{(\textrm{eucl.})} (\boldsymbol{U}')$}
  \COMMENT {Calculate the difference in action}
  \STATE {}
  \COMMENT {\hspace{3mm} for the transition $\boldsymbol{U} \rightarrow \boldsymbol{U}'$}
  \IF {$\Delta S < 0 \, \lor \, \exp \left(- \Delta S \right) > r$}
  \label{code:metroMonteIfCond}
  \COMMENT {with $0 \le r \le 1$ beeing a random}
  \STATE {}
  \COMMENT {\hspace{3mm} number with uniform distribution}
  \STATE $\boldsymbol{U} \rightarrow \boldsymbol{U}'$
  \COMMENT {replace $\boldsymbol{U}$ with $\boldsymbol{U}'$}
  \ENDIF

  \ENDFOR
  \STATE $\left\langle \mathcal{O} \right\rangle \rightarrow \left\langle \mathcal{O} \right\rangle + \frac{\mathcal{O}(\boldsymbol{U})}{N} $
  \COMMENT {Measure $\mathcal{O}(\boldsymbol{U})$}
  \ENDFOR
 \end{algorithmic}
\end{algorithm}
As an initial configuration one usually either chooses a cold starting configuration, i.e. $U_\mu(n)=1$ or a hot one where every link variable is set to a random element of \SUTwo. After that it takes numerous Iterations until the configuration reaches \emph{thermal equilibrium}. A common way to figure out how many iterations this takes, is to run the simulation once with a hot and once with a cold start, and see where the measured values start to agree. Once thermal equilibrium the mean of the measured values will converge towards $\left\langle \mathcal{O} \right\rangle$.


\subsection{The Continous Case}
The first idea that comes to mind for the continuous case is just to pick a random point on the sphere. Procedures to find uniformly distributed random points on spheres of arbitrary dimensions are well known \cite{findsource}. One such procedure to get the euclidian coordinates $x_{\textrm{rand}}$ of a random point on $S_n$ would be given by
\begin{align}
    x_{\textrm{rand}} = \frac{1}{\sqrt{\sum_{i=1}^{n+1}(x^i_{\textrm{rand}})^2}} \begin{pmatrix}
      x^1_{\textrm{rand}} \\
      x^2_{\textrm{rand}} \\
      \vdots \\
      x^{n+1}_{\textrm{rand}}
    \end{pmatrix}
    \label{eq:randSpherePoint}
\end{align}
where $\{x^i_{\textrm{rand}}\}$ are random numbers generated by a normal distribution centered at $0$. The problem with this approach is that for high values of $\beta$ line \ref{code:metroMonteIfCond} in the algorithm will quite often evaluate to \texttt{false}, as $\Delta S$ is likely to be big. This leads to little change in the configuration per iteration, and therefore high run times to generate sufficient statistics.

Therefore one usually aims to generate an element $U_\mu^{\textrm{new}}(n)$ which is in the vicinity of the old element $U_\mu^{\textrm{old}}$. This achieved by
\begin{align*}
  U_\mu^{\textrm{new}}(n) = T \, U_\mu^{\textrm{old}}
\end{align*}
where $T$ is a random group element within the angular distance $\pi \delta$ of 1. T can be found as
\begin{align*}
T = \cos ( \pi d ) + \sin (\pi d) \left(i x_1  + j x_2  + k x_3\right)
\end{align*}
where $d$ is a random number uniformly distributed within the interval $[0,\delta]$ and $(x_1,x_2,x_3)$ are a random point on $S_2$ found by applying eq. \ref{eq:randSpherePoint}.

\subsection{Finite Gauge Sets}

Furthermore we require a similar procedure for finite gauge sets. As $\overline{T} $,$\overline{O}$,$\overline{I}$ and




\begin{align*}
  & R = \left\{
 \begin{bmatrix}
  \rho    & \theta  & \theta  & \theta  \\
  -\theta & \rho    & -\theta & \theta  \\
  -\theta & \theta  & \rho    & -\theta \\
  -\theta & -\theta & \theta  & \rho    \\
 \end{bmatrix},
 \begin{bmatrix}
  \rho    & -\theta & \theta  & -\theta \\
  \theta  & \rho    & \theta  & \theta  \\
  -\theta & -\theta & \rho    & \theta  \\
  \theta  & -\theta & -\theta & \rho    \\
 \end{bmatrix},
 \begin{bmatrix}
  \rho    & \theta  & -\theta & -\theta \\
  -\theta & \rho    & \theta  & -\theta \\
  \theta  & -\theta & \rho    & -\theta \\
  \theta  & \theta  & \theta  & \rho    \\
 \end{bmatrix},
 \begin{bmatrix}
  \rho    & -\theta & -\theta & \theta  \\
  \theta  & \rho    & -\theta & -\theta \\
  \theta  & \theta  & \rho    & \theta  \\
  -\theta & \theta  & -\theta & \rho    \\
 \end{bmatrix}
 \right\}                                                                                                        \\\\
  & \textrm{with} \qquad \rho = \frac{1 + 3\sqrt{5}}{8} \qquad \textrm{and} \qquad \theta = \frac{1-\sqrt{5}}{8}
\end{align*}





\begin{algorithm}[!htb]
 \caption{Neighbour Vertex Algorithm}
 \label{alg:metroMonte}
 \begin{algorithmic}[1]
  \IF {Hello World}
  \ENDIF
 \end{algorithmic}
\end{algorithm}


% \begin{itemize}
%   \item Vielleicht n√ºtzlich \url{https://link.springer.com/content/pdf/10.1007/BF01548769.pdf}
% \end{itemize}


%  https://journals.aps.org/prd/pdf/10.1103/PhysRevD.22.2465
